{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Agent Research & Summarization Workflow\n",
        "\n",
        "# Technologies: Python, LangGraph, OpenAI GPT-3.5, TypedDict\n",
        "Developed a multi-agent AI workflow with LangGraph and GPT-3.5, enabling automated research, summarization, and stateful coordination between agents."
      ],
      "metadata": {
        "id": "L1Ix_FWGBhH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm3DhaZXAm9E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import OpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict\n",
        "from getpass import getpass # Import getpass\n",
        "\n",
        "# Set up the OpenAI model\n",
        "# Retrieve the API key directly in this cell\n",
        "openai_api_key = getpass(\"Enter your OpenAI API Key: \")\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", api_key=openai_api_key)\n",
        "\n",
        "\n",
        "# Define a state to pass between agents\n",
        "class ResearchState(TypedDict):\n",
        "    research_data: str\n",
        "    summary: str\n",
        "\n",
        "# Agent functions\n",
        "def research_agent(state: ResearchState) -> ResearchState:\n",
        "    prompt = \"Research eco-friendly products and provide 2-3 sentences about them.\"\n",
        "    state[\"research_data\"] = llm.invoke(prompt) # Use invoke() instead of __call__() for newer LangChain versions\n",
        "    return state\n",
        "\n",
        "def summarize_agent(state: ResearchState) -> ResearchState:\n",
        "    prompt = f\"Summarize this in one sentence: {state['research_data']}\"\n",
        "    state[\"summary\"] = llm.invoke(prompt) # Use invoke() instead of __call__() for newer LangChain versions\n",
        "    return state\n",
        "\n",
        "# Build the workflow graph\n",
        "workflow = StateGraph(ResearchState)\n",
        "workflow.add_node(\"researcher\", research_agent)\n",
        "workflow.add_node(\"summarizer\", summarize_agent)\n",
        "workflow.add_edge(\"researcher\", \"summarizer\")\n",
        "workflow.add_edge(\"summarizer\", END)\n",
        "workflow.set_entry_point(\"researcher\")\n",
        "\n",
        "# Compile and run\n",
        "app = workflow.compile()\n",
        "initial_state = {\"research_data\": \"\", \"summary\": \"\"}\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "# Show results\n",
        "print(\"Research Data:\", result[\"research_data\"])\n",
        "print(\"Summary:\", result[\"summary\"])"
      ]
    }
  ]
}